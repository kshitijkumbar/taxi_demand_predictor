{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.config as config\n",
    "import hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/42132\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "# Connect to project\n",
    "project = hopsworks.login(\n",
    "    project=config.HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value=config.HOPSWORKS_API_KEY\n",
    ")\n",
    "\n",
    "# Connect to feature store\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    "# Connect to the feature group\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view already existed. Skip creation...\n"
     ]
    }
   ],
   "source": [
    "# Create feature view\n",
    "# Feature view uses only one feature group\n",
    "\n",
    "try:\n",
    "    # Create feature view if one doesn't exist\n",
    "    feature_store.create_feature_view(\n",
    "        name=config.FEATURE_VIEW_NAME,\n",
    "        version=config.FEATURE_VIEW_VERSION,\n",
    "        query=feature_group.select_all()\n",
    "    )\n",
    "\n",
    "except:\n",
    "    print('Feature view already existed. Skip creation...')\n",
    "\n",
    "\n",
    "# Get feature view\n",
    "feature_view = feature_store.get_feature_view(\n",
    "    name=config.FEATURE_VIEW_NAME,\n",
    "    version=config.FEATURE_VIEW_VERSION\n",
    ")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-08 20:50:05,403 INFO: USE `ml_prod_pipline_featurestore`\n",
      "2023-05-08 20:50:05,886 INFO: SELECT `fg0`.`pickup_hour` `pickup_hour`, `fg0`.`rides` `rides`, `fg0`.`pickup_loc_id` `pickup_loc_id`\n",
      "FROM `ml_prod_pipline_featurestore`.`ts_hourly_feat_group_1` `fg0`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'Timestamp' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ts_data, _ \u001b[39m=\u001b[39m feature_view\u001b[39m.\u001b[39;49mtraining_data(\n\u001b[1;32m      2\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTime series hourly taxi rides\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-fQTkBc7N-py3.9/lib/python3.9/site-packages/hsfs/feature_view.py:768\u001b[0m, in \u001b[0;36mFeatureView.training_data\u001b[0;34m(self, start_time, end_time, description, statistics_config, read_options)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[39mGet training data from feature groups.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    752\u001b[0m \n\u001b[1;32m    753\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    754\u001b[0m td \u001b[39m=\u001b[39m training_dataset\u001b[39m.\u001b[39mTrainingDataset(\n\u001b[1;32m    755\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    756\u001b[0m     version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    766\u001b[0m     training_dataset_type\u001b[39m=\u001b[39mtraining_dataset\u001b[39m.\u001b[39mTrainingDataset\u001b[39m.\u001b[39mIN_MEMORY,\n\u001b[1;32m    767\u001b[0m )\n\u001b[0;32m--> 768\u001b[0m td, df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feature_view_engine\u001b[39m.\u001b[39;49mget_training_data(\n\u001b[1;32m    769\u001b[0m     \u001b[39mself\u001b[39;49m, read_options, training_dataset_obj\u001b[39m=\u001b[39;49mtd\n\u001b[1;32m    770\u001b[0m )\n\u001b[1;32m    771\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    772\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mIncremented version to `\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(td\u001b[39m.\u001b[39mversion),\n\u001b[1;32m    773\u001b[0m     util\u001b[39m.\u001b[39mVersionWarning,\n\u001b[1;32m    774\u001b[0m )\n\u001b[1;32m    775\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-fQTkBc7N-py3.9/lib/python3.9/site-packages/hsfs/core/feature_view_engine.py:197\u001b[0m, in \u001b[0;36mFeatureViewEngine.get_training_data\u001b[0;34m(self, feature_view_obj, read_options, splits, training_dataset_obj, training_dataset_version)\u001b[0m\n\u001b[1;32m    188\u001b[0m     query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_batch_query(\n\u001b[1;32m    189\u001b[0m         feature_view_obj,\n\u001b[1;32m    190\u001b[0m         start_time\u001b[39m=\u001b[39mtd_updated\u001b[39m.\u001b[39mevent_start_time,\n\u001b[1;32m    191\u001b[0m         end_time\u001b[39m=\u001b[39mtd_updated\u001b[39m.\u001b[39mevent_end_time,\n\u001b[1;32m    192\u001b[0m         with_label\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    193\u001b[0m     )\n\u001b[1;32m    194\u001b[0m     split_df \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39mget_instance()\u001b[39m.\u001b[39mget_training_data(\n\u001b[1;32m    195\u001b[0m         td_updated, feature_view_obj, query, read_options\n\u001b[1;32m    196\u001b[0m     )\n\u001b[0;32m--> 197\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_training_dataset_statistics(\n\u001b[1;32m    198\u001b[0m         feature_view_obj, td_updated, split_df, calc_stat\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    199\u001b[0m     )\n\u001b[1;32m    201\u001b[0m \u001b[39m# split df into features and labels df\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m td_updated\u001b[39m.\u001b[39msplits:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-fQTkBc7N-py3.9/lib/python3.9/site-packages/hsfs/core/feature_view_engine.py:341\u001b[0m, in \u001b[0;36mFeatureViewEngine.compute_training_dataset_statistics\u001b[0;34m(self, feature_view_obj, training_dataset_obj, td_df, calc_stat)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_statistics_engine\u001b[39m.\u001b[39mregister_split_statistics(\n\u001b[1;32m    336\u001b[0m         training_dataset_obj,\n\u001b[1;32m    337\u001b[0m         feature_dataframes\u001b[39m=\u001b[39mtd_df,\n\u001b[1;32m    338\u001b[0m         feature_view_obj\u001b[39m=\u001b[39mfeature_view_obj,\n\u001b[1;32m    339\u001b[0m     )\n\u001b[1;32m    340\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 341\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_statistics_engine\u001b[39m.\u001b[39;49mcompute_statistics(\n\u001b[1;32m    342\u001b[0m         training_dataset_obj,\n\u001b[1;32m    343\u001b[0m         feature_dataframe\u001b[39m=\u001b[39;49mtd_df,\n\u001b[1;32m    344\u001b[0m         feature_view_obj\u001b[39m=\u001b[39;49mfeature_view_obj,\n\u001b[1;32m    345\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-fQTkBc7N-py3.9/lib/python3.9/site-packages/hsfs/core/statistics_engine.py:60\u001b[0m, in \u001b[0;36mStatisticsEngine.compute_statistics\u001b[0;34m(self, metadata_instance, feature_dataframe, feature_group_commit_id, feature_view_obj)\u001b[0m\n\u001b[1;32m     56\u001b[0m         feature_dataframe \u001b[39m=\u001b[39m metadata_instance\u001b[39m.\u001b[39mread()\n\u001b[1;32m     58\u001b[0m commit_time \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mfloat\u001b[39m(datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mtimestamp()) \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m content_str \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprofile_statistics(metadata_instance, feature_dataframe)\n\u001b[1;32m     61\u001b[0m \u001b[39mif\u001b[39;00m content_str:\n\u001b[1;32m     62\u001b[0m     stats \u001b[39m=\u001b[39m statistics\u001b[39m.\u001b[39mStatistics(\n\u001b[1;32m     63\u001b[0m         commit_time\u001b[39m=\u001b[39mcommit_time,\n\u001b[1;32m     64\u001b[0m         content\u001b[39m=\u001b[39mcontent_str,\n\u001b[1;32m     65\u001b[0m         feature_group_commit_id\u001b[39m=\u001b[39mfeature_group_commit_id,\n\u001b[1;32m     66\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-fQTkBc7N-py3.9/lib/python3.9/site-packages/hsfs/core/statistics_engine.py:82\u001b[0m, in \u001b[0;36mStatisticsEngine.profile_statistics\u001b[0;34m(metadata_instance, feature_dataframe)\u001b[0m\n\u001b[1;32m     75\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     76\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThere is no data in the entity that you are trying to compute \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mstatistics for. A possible cause might be that you inserted only data \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto the online storage of a feature group.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     79\u001b[0m         category\u001b[39m=\u001b[39mutil\u001b[39m.\u001b[39mStatisticsWarning,\n\u001b[1;32m     80\u001b[0m     )\n\u001b[1;32m     81\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 82\u001b[0m \u001b[39mreturn\u001b[39;00m engine\u001b[39m.\u001b[39;49mget_instance()\u001b[39m.\u001b[39;49mprofile(\n\u001b[1;32m     83\u001b[0m     feature_dataframe,\n\u001b[1;32m     84\u001b[0m     metadata_instance\u001b[39m.\u001b[39;49mstatistics_config\u001b[39m.\u001b[39;49mcolumns,\n\u001b[1;32m     85\u001b[0m     metadata_instance\u001b[39m.\u001b[39;49mstatistics_config\u001b[39m.\u001b[39;49mcorrelations,\n\u001b[1;32m     86\u001b[0m     metadata_instance\u001b[39m.\u001b[39;49mstatistics_config\u001b[39m.\u001b[39;49mhistograms,\n\u001b[1;32m     87\u001b[0m     metadata_instance\u001b[39m.\u001b[39;49mstatistics_config\u001b[39m.\u001b[39;49mexact_uniqueness,\n\u001b[1;32m     88\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-fQTkBc7N-py3.9/lib/python3.9/site-packages/hsfs/engine/python.py:283\u001b[0m, in \u001b[0;36mEngine.profile\u001b[0;34m(self, df, relevant_columns, correlations, histograms, exact_uniqueness)\u001b[0m\n\u001b[1;32m    281\u001b[0m final_stats \u001b[39m=\u001b[39m []\n\u001b[1;32m    282\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m stats\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m--> 283\u001b[0m     stat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_pandas_statistics(stats[col]\u001b[39m.\u001b[39;49mto_dict())\n\u001b[1;32m    284\u001b[0m     stat[\u001b[39m\"\u001b[39m\u001b[39mdataType\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\n\u001b[1;32m    285\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFractional\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(stats[col]\u001b[39m.\u001b[39mdtype, \u001b[39mtype\u001b[39m(np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mfloat64)))\n\u001b[1;32m    287\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mIntegral\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n\u001b[1;32m    289\u001b[0m     stat[\u001b[39m\"\u001b[39m\u001b[39misDataTypeInferred\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfalse\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-fQTkBc7N-py3.9/lib/python3.9/site-packages/hsfs/engine/python.py:308\u001b[0m, in \u001b[0;36mEngine._convert_pandas_statistics\u001b[0;34m(self, stat)\u001b[0m\n\u001b[1;32m    306\u001b[0m     content_dict[\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m stat[\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    307\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m stat \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m stat:\n\u001b[0;32m--> 308\u001b[0m     content_dict[\u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m stat[\u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m*\u001b[39;49m stat[\u001b[39m\"\u001b[39;49m\u001b[39mcount\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    309\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m stat:\n\u001b[1;32m    310\u001b[0m     content_dict[\u001b[39m\"\u001b[39m\u001b[39mmaximum\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m stat[\u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'Timestamp' and 'int'"
     ]
    }
   ],
   "source": [
    "ts_data, _ = feature_view.training_data(\n",
    "    description=\"Time series hourly taxi rides\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import processData2FeatTgt\n",
    "\n",
    "feats, tgts = processData2FeatTgt(\n",
    "    ts_data,\n",
    "    input_feat_len=24*28, # Month\n",
    "    step_size=23,\n",
    ")\n",
    "\n",
    "feats_and_tgts = feats.copy()\n",
    "feats_and_tgts['tgt_rides_nxt_hr'] = tgts\n",
    "\n",
    "print(f\"{feats_and_tgts.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "from pytz import timezone\n",
    "import pandas as pd\n",
    "from src.data_split import trainTestSplit\n",
    "\n",
    "# Training data -> from Jan 2022 up until 2 months ago\n",
    "# Test Data -> last 2 months\n",
    "\n",
    "cutoff_date = pd.to_datetime(date.today() - timedelta(days=28*1))\n",
    "\n",
    "print(f\"{cutoff_date=}\")\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = trainTestSplit(\n",
    "    feats_and_tgts,\n",
    "    cutoff_date,\n",
    "    tgt_col_name=\"tgt_rides_nxt_hr\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-fQTkBc7N-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
